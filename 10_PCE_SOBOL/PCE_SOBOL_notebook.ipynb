{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<div class=\"jumbotron text-left\"><b>\n",
    "This tutorial describes how to use Polynomial Chaos Expansion to perform a global variance-based sensitivity analysis by computing the Sobol indices.</b></div>\n",
    "\n",
    "Nathalie BARTOLI ONERA/DTIS/M2CI \n",
    "\n",
    "Sylvain DUBREUIL ONERA/DTIS/M2CI\n",
    "\n",
    "January 2020"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<p class=\"alert alert-success\" style=\"padding:1em\">\n",
    "To use this notebook, openTurns need to be installed via http://openturns.github.io/openturns/latest/install.html\n",
    "</p>\n",
    "\n",
    "\n",
    "conda config --add channels conda-forge\n",
    "\n",
    "\n",
    "conda install openturns\n",
    "\n",
    "\n",
    "For google colab: add a code cell with the following command\n",
    "\n",
    "!pip install openturns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "The objective is to study the sensitivity of the\n",
    "quantity of interest $F$ to the random input parameter $X$ via\n",
    " a global sensitivity analysis by computing variance based\n",
    "sensitivity indices. Consequently, it is assumed that\n",
    "$X$ is a vector of $d$ independent random variables and $F$ is a random variable of unknown probability\n",
    "distribution.\n",
    "$$F: \\mathbb{R}^d \\rightarrow \\mathbb{R}$$\n",
    "\n",
    "For the purpose of explanation the notation $X_i$ indicates the $i$-th element of a random vector ${X}$, meanwhile the short notation $X_{\\sim i}$ is used to indicate all the input variables but $X_i$.\n",
    "The number of input variables, that is the size of $X$, is indicated by $d$; finally $Y = {F}(X)$ represents a scalar output, computed with a generic black box solver indicated as ${F}$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "The first order sensitivity indices are defined: they are the ratio between the reduction in\n",
    "variance when a variable $X_i$ is fixed and the total variance.\n",
    "$$\n",
    "s_i = \\frac{Var_{X_{i}}\\left[E_{X_{\\sim i}}\\left(Y|X_i\\right)\\right]}{Var\\left(Y\\right)}\n",
    "$$\n",
    "where $E$ represents the expected value, ${Var\\left(Y\\right)}$ is the variance, and \n",
    " the term $Var_{X_{i}}\\left[E_{X_{\\sim i}}\\left(Y|X_i\\right)\\right]$ is the estimated reduction in variance when the parameter $X_i$ is fixed. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "The first sensitivity indices  quantify the reduction in variance if the variable $X_i$ is fixed, and vary between 0 and 1 to give an indication about the relative importance of inputs on a given output.\n",
    "\n",
    "- The considerations above can be rephrased saying that if the sum of the first order indices is\n",
    "equal to 1, the model is additive and minor order interactions between variables are meaningless.\n",
    "\n",
    "- On the contrary, if the sum is smaller than one, then the weight of interactions between\n",
    "input variables is not negligible in the total variance of the response and these interactions\n",
    "need to be investigated more precisely."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Since in practice it might be difficult to consider all the\n",
    "orders, the notion of total indices is used. They are defined as\n",
    "\n",
    "$$\n",
    "s_{T_{i}} = \\frac{E_{X_{\\sim i}}\\left[Var_{X_{i}}\\left(Y|X_{\\sim i}\\right)\\right]}{Var\\left(Y\\right)}\n",
    "$$\n",
    "and represent the expected variance that would be left if all inputs but $X_i$ could be fixed. \n",
    "With the help of the total sensitivity indices, it is possible to get the interaction between the\n",
    "input parameters.\n",
    "\n",
    "Classical methods to estimate these sensitivity indices are based on sampling strategies (McKay 1997, Sobol 93,  Cukier 1975). The method described in the following is based on an approximation of the output by polynomial chaos expansion (PCE) and was introduced by Sudret in 2008. Interest of this approach is its efficiency in terms of numerical cost in the context of our study (low number of input variables\n",
    "and smooth mapping between inputs and outputs) compared to sampling strategies.\n",
    "This approach has been further improved in (Blatman and Sudret 2010) using sparse PCE and will be used in\n",
    "the following."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Assuming that $Y=F(X)$ is a second-order\n",
    "random variable, it can be shown (Cameron and Martin 1947) that:\n",
    "$$ Y=F(X) = \\sum_{j=0}^{\\infty}a_j \\Psi_j(X)$$\n",
    "($L^2$ convergence), where $\\{\\Psi_j\\}_{j\\in \\mathbf{N}}$ is a polynomial basis orthogonal with respect\n",
    "to the probability distribution of $X$ and $a_j$ are unknown coefficients."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "\n",
    "The polynomial basis depends on the distribution of $X$ (given by Tryoen PhD 2011 and by Openturns documentation)\n",
    "![polynome.PNG](polynome.PNG)\n",
    "![PCE_basis.PNG](PCE_basis.PNG)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Normally, this sum is truncated to $N+1$ terms\n",
    "$$ \\hat F(X) = \\sum_{j=0}^{N}a_j \\Psi_j(X)$$\n",
    "\n",
    "where $$ N + 1 = \\frac{(p+d)!}{p! d!}$$ \n",
    "if $p$ is the degree of the polynomial basis.\n",
    "\n",
    "The number of terms can also be reduced by using sparce PCE to have\n",
    "\n",
    "$$ \\hat F(X) = \\sum_{\\alpha \\in {\\cal{A}}}a_\\alpha \\Psi_\\alpha(X)$$\n",
    "where $\\mathrm{card}({\\cal{A}}) \\ll N$.\n",
    "\n",
    "Sparse PCE consists in the construction of a sparse polynomial basis $\\{\\Psi_\\alpha\\}_{\\alpha  \\in {\\cal{A}}}$ where $\\alpha = (\\alpha_1, \\cdots, \\alpha_d)$ is a multiindex\n",
    "used to identify the polynomial acting with the power\n",
    "$\\alpha_i$ on the variable $X_i$. We have $\\sum_{i=1}^{d}|\\alpha_i|=p$ where $p$ is the degree of the polynomial $\\Psi_\\alpha$\n",
    "\n",
    "In the present case, this is achieved by Least Angle Regression (LAR),\n",
    "i.e., unknown coefficients $a_i$ are computed by iteratively\n",
    "solving a mean square problem and selecting, at each iteration,\n",
    "the polynomial which is the most correlated with the\n",
    "residual (see Blatman and Sudret (2011) for details).\n",
    "\n",
    "Then by using the basis orthogonality, the quantity $\\hat F(X)$ is completely determined."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "It should be noted that in practice, identification of the unknown coefficients by LAR requires the evaluation of the function $F$ on a given design of experiments sampled from the input space.\n",
    "\n",
    "Due to the orthogonality of the polynomial basis $\\{\\Psi_\\alpha\\}$ it is possible to write the expectation and the variance in the following form:\n",
    "\n",
    "$$\n",
    "\\left \\{\n",
    "\\begin{array}{l}\n",
    "E[\\hat F]= a_0\\\\\n",
    "Var[\\hat F] =\\sum_{\\alpha \\in {\\cal{A}}}a^2_\\alpha E[\\Psi^2_\\alpha(X)]\n",
    "\\end{array} \\right.\n",
    "$$\n",
    "where $E [\\hat F]$ is the mean value and $Var[\\hat F]$ is the variance of the output variable $\\hat F$. \n",
    "\n",
    "In addition, the idea pointed out in Sudret (2008) is to identify the PCE with the ANOVA decomposition, from\n",
    "which one can show that, the first-order sensitivity index of the variable $X_i$ reads:\n",
    "$$\n",
    "\t\\hat{S}_i = \\frac{\\sum_{\\alpha \\in L_i}a^2_{\\alpha}E[\\phi_{\\alpha}^2(X)]}{  Var[\\hat{F}]}\n",
    "$$ \n",
    "where $L_i=\\left\\lbrace \\alpha\\in\\mathcal{A},~ \\forall~j\\neq i~\\alpha_j=0 \\right\\rbrace$, i.e. only the polynomials acting exclusively on the variable $X_i$ are considered. \n",
    "\t\n",
    "The total sensitivity index is also available by, \n",
    "\t$$\n",
    "\t\\hat{S}_{T_i} = \\frac{\\sum_{\\alpha \\in L^+_i}a^2_{\\alpha}E[\\phi_{\\alpha}^2(X)]}{Var[\\hat{F}]}\n",
    "\t$$\n",
    "where $L^{+}_i=\\left\\lbrace \\alpha\\in\\mathcal{A},~ \\alpha_i\\neq 0 \\right\\rbrace$ {i.e.} all the polynomials acting on the variable $X_i$ are considered (allows to consider interactions between $X_i$ and the other variables). \n",
    "\t\n",
    "One can note that the approximation of the sensitivity index obtained by sparse PCE relies on an accurate approximation of the model response by the sparse PCE, however the link between the accuracy of the PCE approximation and the accuracy of the approximated sensitivity index is not straightforward. In order to access the quality of the sensitivity index computed by PCE, a bootstrap approach proposed in Dubreuil 2014 is set up and detailed in the next section.\n",
    "\t"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# References\n",
    "\n",
    "Cameron, R. H., & Martin, W. T. (1947). The orthogonal development of non-linear functionals in series of Fourier-Hermite functionals. Annals of Mathematics, 385-392.\n",
    "\n",
    "Cukier, R. I., Schaibly, J. H., & Shuler, K. E. (1975). Study of the sensitivity of coupled reaction systems to uncertainties in rate coefficients. III. Analysis of the approximations. The Journal of Chemical Physics, 63(3), 1140-1149.\n",
    "\n",
    "Sobol, I. M. (1993). Sensitivity estimates for nonlinear mathematical models. Mathematical modelling and computational experiments, 1(4), 407-414.\n",
    "\n",
    "McKay, M. D. (1997). Nonparametric variance-based methods of assessing uncertainty importance. Reliability engineering & system safety, 57(3), 267-279.\n",
    "\n",
    "Saltelli, A., Tarantola, S., Campolongo, F., & Ratto, M. (2004). Sensitivity analysis in practice: a guide to assessing scientific models. Chichester, England.\n",
    "\n",
    "Sudret, B. (2008). Global sensitivity analysis using polynomial chaos expansions. Reliability engineering & system safety, 93(7), 964-979.\n",
    "\n",
    "Blatman, G., & Sudret, B. (2010). Efficient computation of global sensitivity indices using sparse polynomial chaos expansions. Reliability Engineering & System Safety, 95(11), 1216-1229.\n",
    "\n",
    "Tryoen, J. (2011). Méthodes de Galerkin stochastiques adaptatives pour la propagation d'incertitudes paramétriques dans les modèles hyperboliques (Doctoral dissertation, Université Paris-Est).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# 1. Example on the Ishigami function (from OpenTurns documentation)\n",
    "\n",
    "# Create a polynomial chaos for the Ishigami function\n",
    "\n",
    "In this example, we create a polynomial chaos for the Ishigami function. We create a sparse polynomial with maximum total degree equal to 8. \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Let $a=7$ and $b=0.1$. We consider the function \n",
    "\n",
    "$$\n",
    "g(X_1,X_2,X_3) = \\sin(X_1)+a \\sin (X_2)^2 + b X_3^4 \\sin(X_1)\n",
    "$$\n",
    "\n",
    "for any $X_1,X_2,X_3\\in[-\\pi,\\pi]$ \n",
    "\n",
    "We assume that the random variables $X_1,X_2,X_3$ are independent and have the uniform marginal distribution in the interval from $-\\pi$ to $\\pi$:\n",
    "\n",
    "$$\n",
    "X_1,X_2,X_3\\sim \\mathcal{U}(-\\pi,\\pi).\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Analysis \n",
    "\n",
    "The expectation and the variance of $Y$ are \n",
    "\n",
    "$$\n",
    "E(Y)  = \\frac{a}{2}\n",
    "$$\n",
    "\n",
    "and \n",
    "\n",
    "$$\n",
    "V(Y) = \\frac{1}{2} +  \\frac{a^2}{8} +  \\frac{b^2 \\pi^8}{18} +  \\frac{b\\pi^4}{5}.\n",
    "$$\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "The Sobol' decomposition variances are\n",
    "\n",
    "\\begin{eqnarray*}\n",
    "V_1     &=& \\frac{1}{2} \\left(1 + b\\frac{\\pi^4}{5} \\right)^2 \\\\\n",
    "V_2     &=& \\frac{a^2}{8} \\\\\n",
    "V_{1,3} &=& b^2 \\pi^8 \\frac{8}{225} \\\\\n",
    "\\end{eqnarray*}\n",
    "\n",
    "and $V_3=V_{1,2} = V_{2,3}=V_{1,2,3} = 0$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "This leads to the following first order Sobol' indices:\n",
    "\n",
    "$$\n",
    "S_1 = \\frac{V_1}{V(Y)}, \\qquad S_2 = \\frac{V_2}{V(Y)}, \\qquad S_3 = 0,\n",
    "$$\n",
    "\n",
    "and the following total order indices:\n",
    "\n",
    "$$\n",
    "ST_1 = \\frac{V_1+V_{1,3}}{V(Y)}, \\qquad ST_2 = S_2, \\qquad S_3 = \\frac{V_{1,3}}{V(Y)}.\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "The third variable $X_3$ has no effect at first order (because $X_3^4$ it is multiplied by $\\sin(X_1)$), but has a total effet because of the interactions with $X_1$. On the other hand, the second variable $X_2$ has no interaction which implies that the first order indice is equal to the total order indice for this input variable."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## References\n",
    "\n",
    "* Ishigami, T., & Homma, T. (1990, December). An importance quantification technique in uncertainty analysis for computer models. In Uncertainty Modeling and Analysis, 1990. Proceedings., First International Symposium on (pp. 398-403). IEEE.\n",
    "\n",
    "* Sobol', I. M., & Levitan, Y. L. (1999). On the use of variance reducing multipliers in Monte Carlo computations of a global sensitivity index. Computer Physics Communications, 117(1), 52-61.\n",
    "\n",
    "* Saltelli, A., Chan, K., & Scott, E. M. (Eds.). (2000). Sensitivity analysis (Vol. 134). New York: Wiley.\n",
    "\n",
    "* Crestaux, T., Martinez, J.-M., Le Maitre, O., & Lafitte, O. (2007). Polynomial chaos expansion for uncertainties quantification and sensitivity analysis. SAMO 2007, http://samo2007.chem.elte.hu/lectures/Crestaux.pdf."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Define the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "import openturns as ot\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Create the Ishigami test function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "ot.RandomGenerator.SetSeed(0)\n",
    "formula = ['sin(X1) + 7. * sin(X2)^2 + 0.1 * X3^4 * sin(X1)']\n",
    "input_names = ['X1', 'X2', 'X3']\n",
    "g = ot.SymbolicFunction(input_names, formula)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Create the probabilistic model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "inputDimension = 3\n",
    "distributionList = [ot.Uniform(-np.pi, np.pi)] * inputDimension\n",
    "distribution = ot.ComposedDistribution(distributionList)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Sample the  function and create the database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "N = 50\n",
    "inputSample = distribution.getSample(N)\n",
    "outputSample = g(inputSample)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Create the chaos.\n",
    "\n",
    "We could use only the input and output training samples: in this case, the distribution of the input samples is computed by selecting the best distribution that fits the data. \n",
    "\n",
    "We will create 3 metamodels from the training set using different techniques in order to compare them at the end on a validation basis\n",
    "\n",
    "\n",
    " \n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    " * model1: a PCE metamodel without specifying the polynomial basis and using sparse least square for the computation of the coefficients.\n",
    " \n",
    " * model2: a PCE metamodel giving the polynomial basis orthogonal with respect to the input distribution and using ordinary least square for the computation of the coefficients.\n",
    " \n",
    " * model3: a PCE metamodel giving the polynomial basis orthogonal with respect to the input distribution and using sparse least square for the computation of the coefficients."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Basis size 20\n"
     ]
    }
   ],
   "source": [
    "#complete metamodel without specifying the polynomial basis\n",
    "chaosalgo_1 = ot.FunctionalChaosAlgorithm(inputSample, outputSample)\n",
    "chaosalgo_1.run()\n",
    "results_1 = chaosalgo_1.getResult()\n",
    "print('Basis size',len(np.array(results_1.getCoefficients())))\n",
    "metamodel_1 = results_1.getMetaModel()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.30058 + 1.71303 * (-0.0305351 + 1.66973 * x0) + 0.448775 * (0.151976 + 1.66136 * x1) - 0.83022 * (-1.16576 + 0.273181 * x1 + 3.21241 * x1^2) - 0.191756 * (-1.25775 + 0.180734 * x2 + 3.40709 * x2^2) - 0.933849 * (0.0304292 - 3.98479 * x0 - 0.107743 * x0^2 + 6.35965 * x0^3) - 0.438949 * ((-0.0305351 + 1.66973 * x0) * (0.176935 + 1.65877 * x2)) - 0.361481 * ((0.151976 + 1.66136 * x1) * (0.176935 + 1.65877 * x2)) - 1.8506 * (1.17348 - 0.566228 * x1 - 11.1625 * x1^2 + 1.033 * x1^3 + 12.5747 * x1^4) + 0.152945 * (1.35566 - 0.591639 * x2 - 11.6103 * x2^2 + 0.888199 * x2^3 + 13.1145 * x2^4) + 1.34835 * ((-0.0305351 + 1.66973 * x0) * (-1.25775 + 0.180734 * x2 + 3.40709 * x2^2)) + 0.587606 * ((0.151976 + 1.66136 * x1) * (-1.25775 + 0.180734 * x2 + 3.40709 * x2^2)) - 0.0981944 * (-1.16664 - 0.175028 * x0 + 23.757 * x0^2 + 0.876997 * x0^3 - 69.5918 * x0^4 - 0.83262 * x0^5 + 50.0506 * x0^6) + 1.56084 * (-1.17535 + 0.860792 * x1 + 23.8235 * x1^2 - 4.28814 * x1^3 - 69.5523 * x1^4 + 4.05273 * x1^5 + 49.893 * x1^6) - 0.25775 * ((-0.0305351 + 1.66973 * x0) * (-0.150529 - 3.99471 * x1 + 0.526423 * x1^2 + 6.33555 * x1^3)) + 0.144923 * ((-0.150529 - 3.99471 * x1 + 0.526423 * x1^2 + 6.33555 * x1^3) * (0.176935 + 1.65877 * x2)) - 0.37314 * ((-0.0305351 + 1.66973 * x0) * (-0.202113 - 3.89842 * x2 + 0.448042 * x2^2 + 6.44036 * x2^3)) - 0.151674 * ((0.151976 + 1.66136 * x1) * (-0.202113 - 3.89842 * x2 + 0.448042 * x2^2 + 6.44036 * x2^3)) - 0.190466 * (1.17608 - 1.15576 * x1 - 41.1936 * x1^2 + 10.9474 * x1^3 + 221.583 * x1^4 - 25.0807 * x1^5 - 376.972 * x1^6 + 16.0524 * x1^7 + 198.728 * x1^8) + 0.254573 * (1.30801 - 1.45551 * x2 - 42.0841 * x2^2 + 11.2531 * x2^3 + 224.827 * x2^4 - 22.8718 * x2^5 - 384.389 * x2^6 + 13.4772 * x2^7 + 204.28 * x2^8)\n"
     ]
    }
   ],
   "source": [
    "print(results_1.getComposedMetaModel())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "Since the input distribution is known in our particular case, we can create the multivariate basis from the distribution.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Basis size 165\n"
     ]
    }
   ],
   "source": [
    "#complete metamodel  giving  the polynomial basis\n",
    "multivariateBasis = ot.OrthogonalProductPolynomialFactory(distributionList)\n",
    "totalDegree = 8\n",
    "enumfunc = multivariateBasis.getEnumerateFunction()\n",
    "P = enumfunc.getStrataCumulatedCardinal(totalDegree)\n",
    "adaptiveStrategy = ot.FixedStrategy(multivariateBasis, P)\n",
    "chaosalgo_2 = ot.FunctionalChaosAlgorithm(inputSample, outputSample, distribution, adaptiveStrategy)\n",
    "chaosalgo_2.run()\n",
    "results_2 = chaosalgo_2.getResult()\n",
    "print('Basis size',len(np.array(results_2.getCoefficients())))\n",
    "\n",
    "metamodel_2 = results_2.getMetaModel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P number of coefficients 165\n",
      "1.61233 + 0.668759 * (1.73205 * x0) + 0.123029 * (1.73205 * x1) - 0.388916 * (1.73205 * x2) - 0.220215 * (-1.11803 + 3.3541 * x0^2) + 0.00393096 * ((1.73205 * x0) * (1.73205 * x1)) - 0.404316 * ((1.73205 * x0) * (1.73205 * x2)) - 0.658872 * (-1.11803 + 3.3541 * x1^2) + 0.0486094 * ((1.73205 * x1) * (1.73205 * x2)) - 0.194032 * (-1.11803 + 3.3541 * x2^2) - 0.482695 * (-3.96863 * x0 + 6.61438 * x0^3) - 0.0809533 * ((-1.11803 + 3.3541 * x0^2) * (1.73205 * x1)) + 0.0122978 * ((-1.11803 + 3.3541 * x0^2) * (1.73205 * x2)) - 0.193811 * ((1.73205 * x0) * (-1.11803 + 3.3541 * x1^2)) + 0.279749 * ((1.73205 * x0) * (1.73205 * x1) * (1.73205 * x2)) + 0.124826 * ((1.73205 * x0) * (-1.11803 + 3.3541 * x2^2)) - 0.232557 * (-3.96863 * x1 + 6.61438 * x1^3) + 0.0724672 * ((-1.11803 + 3.3541 * x1^2) * (1.73205 * x2)) + 0.243673 * ((1.73205 * x1) * (-1.11803 + 3.3541 * x2^2)) + 0.0364312 * (-3.96863 * x2 + 6.61438 * x2^3) - 0.0954637 * (1.125 - 11.25 * x0^2 + 13.125 * x0^4) - 0.0745929 * ((-3.96863 * x0 + 6.61438 * x0^3) * (1.73205 * x1)) + 0.223087 * ((-3.96863 * x0 + 6.61438 * x0^3) * (1.73205 * x2)) + 0.188902 * ((-1.11803 + 3.3541 * x0^2) * (-1.11803 + 3.3541 * x1^2)) - 0.0334867 * ((-1.11803 + 3.3541 * x0^2) * (1.73205 * x1) * (1.73205 * x2)) - 0.0223936 * ((-1.11803 + 3.3541 * x0^2) * (-1.11803 + 3.3541 * x2^2)) - 0.114165 * ((1.73205 * x0) * (-3.96863 * x1 + 6.61438 * x1^3)) - 0.0547024 * ((1.73205 * x0) * (-1.11803 + 3.3541 * x1^2) * (1.73205 * x2)) - 0.192002 * ((1.73205 * x0) * (1.73205 * x1) * (-1.11803 + 3.3541 * x2^2)) - 0.0285436 * ((1.73205 * x0) * (-3.96863 * x2 + 6.61438 * x2^3)) - 0.654769 * (1.125 - 11.25 * x1^2 + 13.125 * x1^4) - 0.0766276 * ((-3.96863 * x1 + 6.61438 * x1^3) * (1.73205 * x2)) + 0.170305 * ((-1.11803 + 3.3541 * x1^2) * (-1.11803 + 3.3541 * x2^2)) - 0.450385 * ((1.73205 * x1) * (-3.96863 * x2 + 6.61438 * x2^3)) - 0.27079 * (1.125 - 11.25 * x2^2 + 13.125 * x2^4) + 0.073311 * (6.21867 * x0 - 29.0205 * x0^3 + 26.1184 * x0^5) - 0.114501 * ((1.125 - 11.25 * x0^2 + 13.125 * x0^4) * (1.73205 * x1)) + 0.00535086 * ((1.125 - 11.25 * x0^2 + 13.125 * x0^4) * (1.73205 * x2)) + 0.0533222 * ((-3.96863 * x0 + 6.61438 * x0^3) * (-1.11803 + 3.3541 * x1^2)) - 0.0252383 * ((-3.96863 * x0 + 6.61438 * x0^3) * (1.73205 * x1) * (1.73205 * x2)) - 0.287714 * ((-3.96863 * x0 + 6.61438 * x0^3) * (-1.11803 + 3.3541 * x2^2)) + 0.11871 * ((-1.11803 + 3.3541 * x0^2) * (-3.96863 * x1 + 6.61438 * x1^3)) + 0.182237 * ((-1.11803 + 3.3541 * x0^2) * (-1.11803 + 3.3541 * x1^2) * (1.73205 * x2)) - 0.442417 * ((-1.11803 + 3.3541 * x0^2) * (1.73205 * x1) * (-1.11803 + 3.3541 * x2^2)) + 0.189103 * ((-1.11803 + 3.3541 * x0^2) * (-3.96863 * x2 + 6.61438 * x2^3)) + 0.0294712 * ((1.73205 * x0) * (1.125 - 11.25 * x1^2 + 13.125 * x1^4)) - 0.203875 * ((1.73205 * x0) * (-3.96863 * x1 + 6.61438 * x1^3) * (1.73205 * x2)) - 0.0236593 * ((1.73205 * x0) * (-1.11803 + 3.3541 * x1^2) * (-1.11803 + 3.3541 * x2^2)) - 0.421372 * ((1.73205 * x0) * (1.73205 * x1) * (-3.96863 * x2 + 6.61438 * x2^3)) + 0.147594 * ((1.73205 * x0) * (1.125 - 11.25 * x2^2 + 13.125 * x2^4)) + 0.0858053 * (6.21867 * x1 - 29.0205 * x1^3 + 26.1184 * x1^5) + 0.195859 * ((1.125 - 11.25 * x1^2 + 13.125 * x1^4) * (1.73205 * x2)) - 0.138387 * ((-3.96863 * x1 + 6.61438 * x1^3) * (-1.11803 + 3.3541 * x2^2)) - 0.155808 * ((-1.11803 + 3.3541 * x1^2) * (-3.96863 * x2 + 6.61438 * x2^3)) + 0.0218195 * ((1.73205 * x1) * (1.125 - 11.25 * x2^2 + 13.125 * x2^4)) - 0.0700166 * (6.21867 * x2 - 29.0205 * x2^3 + 26.1184 * x2^5) - 0.515737 * (-1.12673 + 23.6614 * x0^2 - 70.9843 * x0^4 + 52.0551 * x0^6) + 0.00269662 * ((6.21867 * x0 - 29.0205 * x0^3 + 26.1184 * x0^5) * (1.73205 * x1)) - 0.166033 * ((6.21867 * x0 - 29.0205 * x0^3 + 26.1184 * x0^5) * (1.73205 * x2)) + 0.150284 * ((1.125 - 11.25 * x0^2 + 13.125 * x0^4) * (-1.11803 + 3.3541 * x1^2)) + 0.00203141 * ((1.125 - 11.25 * x0^2 + 13.125 * x0^4) * (1.73205 * x1) * (1.73205 * x2)) + 0.16419 * ((1.125 - 11.25 * x0^2 + 13.125 * x0^4) * (-1.11803 + 3.3541 * x2^2)) + 0.112946 * ((-3.96863 * x0 + 6.61438 * x0^3) * (-3.96863 * x1 + 6.61438 * x1^3)) + 0.112105 * ((-3.96863 * x0 + 6.61438 * x0^3) * (-1.11803 + 3.3541 * x1^2) * (1.73205 * x2)) - 0.171075 * ((-3.96863 * x0 + 6.61438 * x0^3) * (1.73205 * x1) * (-1.11803 + 3.3541 * x2^2)) + 0.17261 * ((-3.96863 * x0 + 6.61438 * x0^3) * (-3.96863 * x2 + 6.61438 * x2^3)) + 0.145035 * ((-1.11803 + 3.3541 * x0^2) * (1.125 - 11.25 * x1^2 + 13.125 * x1^4)) + 0.150097 * ((-1.11803 + 3.3541 * x0^2) * (-3.96863 * x1 + 6.61438 * x1^3) * (1.73205 * x2)) - 0.101598 * ((-1.11803 + 3.3541 * x0^2) * (-1.11803 + 3.3541 * x1^2) * (-1.11803 + 3.3541 * x2^2)) + 0.341995 * ((-1.11803 + 3.3541 * x0^2) * (1.73205 * x1) * (-3.96863 * x2 + 6.61438 * x2^3)) - 0.00467677 * ((-1.11803 + 3.3541 * x0^2) * (1.125 - 11.25 * x2^2 + 13.125 * x2^4)) + 0.130091 * ((1.73205 * x0) * (6.21867 * x1 - 29.0205 * x1^3 + 26.1184 * x1^5)) + 0.244542 * ((1.73205 * x0) * (1.125 - 11.25 * x1^2 + 13.125 * x1^4) * (1.73205 * x2)) - 0.101937 * ((1.73205 * x0) * (-3.96863 * x1 + 6.61438 * x1^3) * (-1.11803 + 3.3541 * x2^2)) - 0.111965 * ((1.73205 * x0) * (-1.11803 + 3.3541 * x1^2) * (-3.96863 * x2 + 6.61438 * x2^3)) + 0.208767 * ((1.73205 * x0) * (1.73205 * x1) * (1.125 - 11.25 * x2^2 + 13.125 * x2^4)) - 0.0444324 * ((1.73205 * x0) * (6.21867 * x2 - 29.0205 * x2^3 + 26.1184 * x2^5)) + 0.989389 * (-1.12673 + 23.6614 * x1^2 - 70.9843 * x1^4 + 52.0551 * x1^6) - 0.25988 * ((6.21867 * x1 - 29.0205 * x1^3 + 26.1184 * x1^5) * (1.73205 * x2)) + 0.134331 * ((1.125 - 11.25 * x1^2 + 13.125 * x1^4) * (-1.11803 + 3.3541 * x2^2)) + 0.177201 * ((-3.96863 * x1 + 6.61438 * x1^3) * (-3.96863 * x2 + 6.61438 * x2^3)) + 0.0499177 * ((-1.11803 + 3.3541 * x1^2) * (1.125 - 11.25 * x2^2 + 13.125 * x2^4)) - 0.0530031 * ((1.73205 * x1) * (6.21867 * x2 - 29.0205 * x2^3 + 26.1184 * x2^5)) + 0.158381 * (-1.12673 + 23.6614 * x2^2 - 70.9843 * x2^4 + 52.0551 * x2^6) - 0.0240719 * (-8.47215 * x0 + 76.2494 * x0^3 - 167.749 * x0^5 + 103.844 * x0^7) + 0.124288 * ((-1.12673 + 23.6614 * x0^2 - 70.9843 * x0^4 + 52.0551 * x0^6) * (1.73205 * x1)) + 0.169686 * ((-1.12673 + 23.6614 * x0^2 - 70.9843 * x0^4 + 52.0551 * x0^6) * (1.73205 * x2)) + 0.184889 * ((6.21867 * x0 - 29.0205 * x0^3 + 26.1184 * x0^5) * (-1.11803 + 3.3541 * x1^2)) - 0.0913881 * ((6.21867 * x0 - 29.0205 * x0^3 + 26.1184 * x0^5) * (1.73205 * x1) * (1.73205 * x2)) + 0.181944 * ((6.21867 * x0 - 29.0205 * x0^3 + 26.1184 * x0^5) * (-1.11803 + 3.3541 * x2^2)) - 0.00163735 * ((1.125 - 11.25 * x0^2 + 13.125 * x0^4) * (-3.96863 * x1 + 6.61438 * x1^3)) - 0.197688 * ((1.125 - 11.25 * x0^2 + 13.125 * x0^4) * (-1.11803 + 3.3541 * x1^2) * (1.73205 * x2)) + 0.0760857 * ((1.125 - 11.25 * x0^2 + 13.125 * x0^4) * (1.73205 * x1) * (-1.11803 + 3.3541 * x2^2)) + 0.148265 * ((1.125 - 11.25 * x0^2 + 13.125 * x0^4) * (-3.96863 * x2 + 6.61438 * x2^3)) - 0.101705 * ((-3.96863 * x0 + 6.61438 * x0^3) * (1.125 - 11.25 * x1^2 + 13.125 * x1^4)) + 0.0267783 * ((-3.96863 * x0 + 6.61438 * x0^3) * (-3.96863 * x1 + 6.61438 * x1^3) * (1.73205 * x2)) - 0.0043188 * ((-3.96863 * x0 + 6.61438 * x0^3) * (-1.11803 + 3.3541 * x1^2) * (-1.11803 + 3.3541 * x2^2)) + 0.423531 * ((-3.96863 * x0 + 6.61438 * x0^3) * (1.73205 * x1) * (-3.96863 * x2 + 6.61438 * x2^3)) + 0.173578 * ((-3.96863 * x0 + 6.61438 * x0^3) * (1.125 - 11.25 * x2^2 + 13.125 * x2^4)) - 0.134023 * ((-1.11803 + 3.3541 * x0^2) * (6.21867 * x1 - 29.0205 * x1^3 + 26.1184 * x1^5)) - 0.143213 * ((-1.11803 + 3.3541 * x0^2) * (1.125 - 11.25 * x1^2 + 13.125 * x1^4) * (1.73205 * x2)) + 0.236833 * ((-1.11803 + 3.3541 * x0^2) * (-3.96863 * x1 + 6.61438 * x1^3) * (-1.11803 + 3.3541 * x2^2)) + 8.9046e-05 * ((-1.11803 + 3.3541 * x0^2) * (-1.11803 + 3.3541 * x1^2) * (-3.96863 * x2 + 6.61438 * x2^3)) + 0.19552 * ((-1.11803 + 3.3541 * x0^2) * (1.73205 * x1) * (1.125 - 11.25 * x2^2 + 13.125 * x2^4)) - 0.261844 * ((-1.11803 + 3.3541 * x0^2) * (6.21867 * x2 - 29.0205 * x2^3 + 26.1184 * x2^5)) - 0.00763602 * ((1.73205 * x0) * (-1.12673 + 23.6614 * x1^2 - 70.9843 * x1^4 + 52.0551 * x1^6)) - 0.256017 * ((1.73205 * x0) * (6.21867 * x1 - 29.0205 * x1^3 + 26.1184 * x1^5) * (1.73205 * x2)) + 0.296046 * ((1.73205 * x0) * (1.125 - 11.25 * x1^2 + 13.125 * x1^4) * (-1.11803 + 3.3541 * x2^2)) + 0.624951 * ((1.73205 * x0) * (-3.96863 * x1 + 6.61438 * x1^3) * (-3.96863 * x2 + 6.61438 * x2^3)) + 0.188465 * ((1.73205 * x0) * (-1.11803 + 3.3541 * x1^2) * (1.125 - 11.25 * x2^2 + 13.125 * x2^4)) + 0.144053 * ((1.73205 * x0) * (1.73205 * x1) * (6.21867 * x2 - 29.0205 * x2^3 + 26.1184 * x2^5)) - 0.368831 * ((1.73205 * x0) * (-1.12673 + 23.6614 * x2^2 - 70.9843 * x2^4 + 52.0551 * x2^6)) + 0.0592009 * (-8.47215 * x1 + 76.2494 * x1^3 - 167.749 * x1^5 + 103.844 * x1^7) - 0.0652131 * ((-1.12673 + 23.6614 * x1^2 - 70.9843 * x1^4 + 52.0551 * x1^6) * (1.73205 * x2)) + 0.266592 * ((6.21867 * x1 - 29.0205 * x1^3 + 26.1184 * x1^5) * (-1.11803 + 3.3541 * x2^2)) + 0.226144 * ((1.125 - 11.25 * x1^2 + 13.125 * x1^4) * (-3.96863 * x2 + 6.61438 * x2^3)) + 0.287005 * ((-3.96863 * x1 + 6.61438 * x1^3) * (1.125 - 11.25 * x2^2 + 13.125 * x2^4)) + 0.0758523 * ((-1.11803 + 3.3541 * x1^2) * (6.21867 * x2 - 29.0205 * x2^3 + 26.1184 * x2^5)) + 0.313116 * ((1.73205 * x1) * (-1.12673 + 23.6614 * x2^2 - 70.9843 * x2^4 + 52.0551 * x2^6)) + 0.239047 * (-8.47215 * x2 + 76.2494 * x2^3 - 167.749 * x2^5 + 103.844 * x2^7) - 0.0665117 * (1.12741 - 40.5868 * x0^2 + 223.228 * x0^4 - 386.928 * x0^6 + 207.283 * x0^8) + 0.0879648 * ((-8.47215 * x0 + 76.2494 * x0^3 - 167.749 * x0^5 + 103.844 * x0^7) * (1.73205 * x1)) + 0.227341 * ((-8.47215 * x0 + 76.2494 * x0^3 - 167.749 * x0^5 + 103.844 * x0^7) * (1.73205 * x2)) + 0.110706 * ((-1.12673 + 23.6614 * x0^2 - 70.9843 * x0^4 + 52.0551 * x0^6) * (-1.11803 + 3.3541 * x1^2)) + 0.0622605 * ((-1.12673 + 23.6614 * x0^2 - 70.9843 * x0^4 + 52.0551 * x0^6) * (1.73205 * x1) * (1.73205 * x2)) - 0.156903 * ((-1.12673 + 23.6614 * x0^2 - 70.9843 * x0^4 + 52.0551 * x0^6) * (-1.11803 + 3.3541 * x2^2)) + 0.0271446 * ((6.21867 * x0 - 29.0205 * x0^3 + 26.1184 * x0^5) * (-3.96863 * x1 + 6.61438 * x1^3)) - 0.0353643 * ((6.21867 * x0 - 29.0205 * x0^3 + 26.1184 * x0^5) * (-1.11803 + 3.3541 * x1^2) * (1.73205 * x2)) + 0.202535 * ((6.21867 * x0 - 29.0205 * x0^3 + 26.1184 * x0^5) * (1.73205 * x1) * (-1.11803 + 3.3541 * x2^2)) + 0.0540498 * ((6.21867 * x0 - 29.0205 * x0^3 + 26.1184 * x0^5) * (-3.96863 * x2 + 6.61438 * x2^3)) - 0.146267 * ((1.125 - 11.25 * x0^2 + 13.125 * x0^4) * (1.125 - 11.25 * x1^2 + 13.125 * x1^4)) - 0.100114 * ((1.125 - 11.25 * x0^2 + 13.125 * x0^4) * (-3.96863 * x1 + 6.61438 * x1^3) * (1.73205 * x2)) + 0.0676247 * ((1.125 - 11.25 * x0^2 + 13.125 * x0^4) * (-1.11803 + 3.3541 * x1^2) * (-1.11803 + 3.3541 * x2^2)) + 0.287146 * ((1.125 - 11.25 * x0^2 + 13.125 * x0^4) * (1.73205 * x1) * (-3.96863 * x2 + 6.61438 * x2^3)) + 0.0643569 * ((1.125 - 11.25 * x0^2 + 13.125 * x0^4) * (1.125 - 11.25 * x2^2 + 13.125 * x2^4)) - 0.134703 * ((-3.96863 * x0 + 6.61438 * x0^3) * (6.21867 * x1 - 29.0205 * x1^3 + 26.1184 * x1^5)) - 0.0765463 * ((-3.96863 * x0 + 6.61438 * x0^3) * (1.125 - 11.25 * x1^2 + 13.125 * x1^4) * (1.73205 * x2)) + 0.325595 * ((-3.96863 * x0 + 6.61438 * x0^3) * (-3.96863 * x1 + 6.61438 * x1^3) * (-1.11803 + 3.3541 * x2^2)) + 0.139469 * ((-3.96863 * x0 + 6.61438 * x0^3) * (-1.11803 + 3.3541 * x1^2) * (-3.96863 * x2 + 6.61438 * x2^3)) - 0.179746 * ((-3.96863 * x0 + 6.61438 * x0^3) * (1.73205 * x1) * (1.125 - 11.25 * x2^2 + 13.125 * x2^4)) - 0.0117043 * ((-3.96863 * x0 + 6.61438 * x0^3) * (6.21867 * x2 - 29.0205 * x2^3 + 26.1184 * x2^5)) - 0.392187 * ((-1.11803 + 3.3541 * x0^2) * (-1.12673 + 23.6614 * x1^2 - 70.9843 * x1^4 + 52.0551 * x1^6)) - 0.0460958 * ((-1.11803 + 3.3541 * x0^2) * (6.21867 * x1 - 29.0205 * x1^3 + 26.1184 * x1^5) * (1.73205 * x2)) + 0.112306 * ((-1.11803 + 3.3541 * x0^2) * (1.125 - 11.25 * x1^2 + 13.125 * x1^4) * (-1.11803 + 3.3541 * x2^2)) - 0.0934845 * ((-1.11803 + 3.3541 * x0^2) * (-3.96863 * x1 + 6.61438 * x1^3) * (-3.96863 * x2 + 6.61438 * x2^3)) + 0.0864604 * ((-1.11803 + 3.3541 * x0^2) * (-1.11803 + 3.3541 * x1^2) * (1.125 - 11.25 * x2^2 + 13.125 * x2^4)) + 0.197093 * ((-1.11803 + 3.3541 * x0^2) * (1.73205 * x1) * (6.21867 * x2 - 29.0205 * x2^3 + 26.1184 * x2^5)) - 0.161898 * ((-1.11803 + 3.3541 * x0^2) * (-1.12673 + 23.6614 * x2^2 - 70.9843 * x2^4 + 52.0551 * x2^6)) - 0.043708 * ((1.73205 * x0) * (-8.47215 * x1 + 76.2494 * x1^3 - 167.749 * x1^5 + 103.844 * x1^7)) - 0.231737 * ((1.73205 * x0) * (-1.12673 + 23.6614 * x1^2 - 70.9843 * x1^4 + 52.0551 * x1^6) * (1.73205 * x2)) + 0.136046 * ((1.73205 * x0) * (6.21867 * x1 - 29.0205 * x1^3 + 26.1184 * x1^5) * (-1.11803 + 3.3541 * x2^2)) - 0.0157234 * ((1.73205 * x0) * (1.125 - 11.25 * x1^2 + 13.125 * x1^4) * (-3.96863 * x2 + 6.61438 * x2^3)) - 0.180747 * ((1.73205 * x0) * (-3.96863 * x1 + 6.61438 * x1^3) * (1.125 - 11.25 * x2^2 + 13.125 * x2^4)) - 0.0625626 * ((1.73205 * x0) * (-1.11803 + 3.3541 * x1^2) * (6.21867 * x2 - 29.0205 * x2^3 + 26.1184 * x2^5)) - 0.0810873 * ((1.73205 * x0) * (1.73205 * x1) * (-1.12673 + 23.6614 * x2^2 - 70.9843 * x2^4 + 52.0551 * x2^6)) + 0.092657 * ((1.73205 * x0) * (-8.47215 * x2 + 76.2494 * x2^3 - 167.749 * x2^5 + 103.844 * x2^7)) - 0.519317 * (1.12741 - 40.5868 * x1^2 + 223.228 * x1^4 - 386.928 * x1^6 + 207.283 * x1^8) + 0.388518 * ((-8.47215 * x1 + 76.2494 * x1^3 - 167.749 * x1^5 + 103.844 * x1^7) * (1.73205 * x2)) - 0.155855 * ((-1.12673 + 23.6614 * x1^2 - 70.9843 * x1^4 + 52.0551 * x1^6) * (-1.11803 + 3.3541 * x2^2)) + 0.196228 * ((6.21867 * x1 - 29.0205 * x1^3 + 26.1184 * x1^5) * (-3.96863 * x2 + 6.61438 * x2^3)) + 0.2471 * ((1.125 - 11.25 * x1^2 + 13.125 * x1^4) * (1.125 - 11.25 * x2^2 + 13.125 * x2^4)) + 0.0324544 * ((-3.96863 * x1 + 6.61438 * x1^3) * (6.21867 * x2 - 29.0205 * x2^3 + 26.1184 * x2^5)) + 0.265446 * ((-1.11803 + 3.3541 * x1^2) * (-1.12673 + 23.6614 * x2^2 - 70.9843 * x2^4 + 52.0551 * x2^6)) + 0.102982 * ((1.73205 * x1) * (-8.47215 * x2 + 76.2494 * x2^3 - 167.749 * x2^5 + 103.844 * x2^7)) - 0.018503 * (1.12741 - 40.5868 * x2^2 + 223.228 * x2^4 - 386.928 * x2^6 + 207.283 * x2^8)\n"
     ]
    }
   ],
   "source": [
    "print('P number of coefficients',P)\n",
    "print(results_2.getComposedMetaModel())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "We can also compute a sparse basis by penalyzed least square"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Basis size 31\n"
     ]
    }
   ],
   "source": [
    "#sparse metamodel using a sparse polynomial basis\n",
    "multivariateBasis = ot.OrthogonalProductPolynomialFactory(distributionList)\n",
    "totalDegree = 8\n",
    "enumfunc = multivariateBasis.getEnumerateFunction()\n",
    "P = enumfunc.getStrataCumulatedCardinal(totalDegree)\n",
    "adaptiveStrategy = ot.FixedStrategy(multivariateBasis, P)\n",
    "basisSequenceFactory = ot.LARS()\n",
    "fittingAlgorithm = ot.CorrectedLeaveOneOut()\n",
    "approximationAlgorithm = ot.LeastSquaresMetaModelSelectionFactory(\n",
    "    basisSequenceFactory, fittingAlgorithm)\n",
    "evaluationCoeffStrategy = ot.LeastSquaresStrategy(\n",
    "    ot.MonteCarloExperiment(N), approximationAlgorithm)\n",
    "chaosalgo_3 = ot.FunctionalChaosAlgorithm(\n",
    "    inputSample, outputSample, distribution, adaptiveStrategy, evaluationCoeffStrategy)\n",
    "chaosalgo_3.run()\n",
    "results_3 = chaosalgo_3.getResult()\n",
    "print('Basis size',len(np.array(results_3.getCoefficients())))\n",
    "\n",
    "metamodel_3 = results_3.getMetaModel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.52964 + 1.5474 * (1.73205 * x0) + 0.00256929 * (1.73205 * x1) - 0.0807905 * ((1.73205 * x0) * (1.73205 * x2)) - 0.593234 * (-1.11803 + 3.3541 * x1^2) - 0.13846 * ((1.73205 * x1) * (1.73205 * x2)) - 1.19991 * (-3.96863 * x0 + 6.61438 * x0^3) - 0.110548 * ((1.73205 * x0) * (1.73205 * x1) * (1.73205 * x2)) + 1.26727 * ((1.73205 * x0) * (-1.11803 + 3.3541 * x2^2)) + 0.175904 * ((-1.11803 + 3.3541 * x0^2) * (1.73205 * x1) * (1.73205 * x2)) + 0.00654607 * ((1.73205 * x0) * (-1.11803 + 3.3541 * x1^2) * (1.73205 * x2)) - 1.96086 * (1.125 - 11.25 * x1^2 + 13.125 * x1^4) - 0.103697 * ((1.73205 * x1) * (-3.96863 * x2 + 6.61438 * x2^3)) - 0.846024 * ((-3.96863 * x0 + 6.61438 * x0^3) * (-1.11803 + 3.3541 * x2^2)) - 0.0401654 * ((-1.11803 + 3.3541 * x0^2) * (1.73205 * x1) * (-1.11803 + 3.3541 * x2^2)) + 0.341555 * ((1.73205 * x0) * (1.125 - 11.25 * x2^2 + 13.125 * x2^4)) + 0.0639878 * ((-3.96863 * x0 + 6.61438 * x0^3) * (-1.11803 + 3.3541 * x1^2) * (1.73205 * x2)) + 0.0895855 * ((-3.96863 * x0 + 6.61438 * x0^3) * (-3.96863 * x2 + 6.61438 * x2^3)) + 0.155112 * ((-1.11803 + 3.3541 * x0^2) * (1.73205 * x1) * (-3.96863 * x2 + 6.61438 * x2^3)) - 0.0861435 * ((1.73205 * x0) * (-3.96863 * x1 + 6.61438 * x1^3) * (-1.11803 + 3.3541 * x2^2)) + 1.32699 * (-1.12673 + 23.6614 * x1^2 - 70.9843 * x1^4 + 52.0551 * x1^6) - 0.156345 * ((1.125 - 11.25 * x0^2 + 13.125 * x0^4) * (-1.11803 + 3.3541 * x1^2) * (1.73205 * x2)) - 0.0448595 * ((-3.96863 * x0 + 6.61438 * x0^3) * (1.73205 * x1) * (-3.96863 * x2 + 6.61438 * x2^3)) - 0.0206157 * ((-1.11803 + 3.3541 * x0^2) * (1.73205 * x1) * (1.125 - 11.25 * x2^2 + 13.125 * x2^4)) - 0.120638 * ((1.73205 * x0) * (-1.12673 + 23.6614 * x1^2 - 70.9843 * x1^4 + 52.0551 * x1^6)) - 0.041198 * ((1.73205 * x0) * (-3.96863 * x1 + 6.61438 * x1^3) * (-3.96863 * x2 + 6.61438 * x2^3)) - 0.148394 * ((1.73205 * x0) * (-1.11803 + 3.3541 * x1^2) * (1.125 - 11.25 * x2^2 + 13.125 * x2^4)) + 0.103029 * ((1.73205 * x1) * (-1.12673 + 23.6614 * x2^2 - 70.9843 * x2^4 + 52.0551 * x2^6)) + 0.0271669 * ((-3.96863 * x0 + 6.61438 * x0^3) * (-3.96863 * x1 + 6.61438 * x1^3) * (-1.11803 + 3.3541 * x2^2)) - 0.290402 * (1.12741 - 40.5868 * x1^2 + 223.228 * x1^4 - 386.928 * x1^6 + 207.283 * x1^8) + 0.0565358 * (1.12741 - 40.5868 * x2^2 + 223.228 * x2^4 - 386.928 * x2^6 + 207.283 * x2^8)\n"
     ]
    }
   ],
   "source": [
    "print(results_3.getComposedMetaModel())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## PCE metamodel validation\n",
    "\n",
    "Comparison of the 3 created metamodels using a  validation set to compute the predictive error: the lowest is the error, the closest to 1 is the predictive factor $Q_2$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model 1 0.8358773054848923\n",
      "model 2 0.0017967681881030373\n",
      "model 3 0.9708968118132157\n"
     ]
    }
   ],
   "source": [
    "n_valid = 1000\n",
    "inputTest = distribution.getSample(n_valid)\n",
    "outputTest = g(inputTest)\n",
    "val_1 = ot.MetaModelValidation(inputTest, outputTest, metamodel_1)\n",
    "val_2 = ot.MetaModelValidation(inputTest, outputTest, metamodel_2)\n",
    "val_3 = ot.MetaModelValidation(inputTest, outputTest, metamodel_3)\n",
    "Q2_1 = val_1.computePredictivityFactor()\n",
    "Q2_2 = val_2.computePredictivityFactor()\n",
    "Q2_3 = val_3.computePredictivityFactor()\n",
    "print('model 1', Q2_1)\n",
    "print('model 2', Q2_2)\n",
    "print('model 3', Q2_3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Computation of the sensitivity indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Indices with model 1\n",
      " input dimension: 3\n",
      " output dimension: 1\n",
      " basis size: 16\n",
      " mean: [3.53811]\n",
      " std-dev: [3.28167]\n",
      "------------------------------------------------------------\n",
      "Index   | Multi-indice                  | Part of variance  \n",
      "------------------------------------------------------------\n",
      "      8 | [0,4,0]                       | 0.325748\n",
      "      1 | [1,0,0]                       | 0.160083\n",
      "     12 | [0,6,0]                       | 0.153514\n",
      "     11 | [1,0,2]                       | 0.10297\n",
      "      4 | [3,0,0]                       | 0.096426\n",
      "     15 | [0,8,0]                       | 0.054614\n",
      "      3 | [0,2,0]                       | 0.0344765\n",
      "     13 | [0,1,3]                       | 0.0217326\n",
      "      2 | [0,1,0]                       | 0.0153157\n",
      "      5 | [0,3,0]                       | 0.0128456\n",
      "      7 | [0,1,1]                       | 0.0119246\n",
      "------------------------------------------------------------\n",
      "\n",
      "\n",
      "------------------------------------------------------------\n",
      "Component | Sobol index            | Sobol total index      \n",
      "------------------------------------------------------------\n",
      "        0 | 0.256509               | 0.359479              \n",
      "        1 | 0.59652                | 0.634652              \n",
      "        2 | 0.00586869             | 0.146971              \n",
      "------------------------------------------------------------\n",
      "\n",
      "\n",
      "######################\n",
      "Indices with model 2\n",
      " input dimension: 3\n",
      " output dimension: 1\n",
      " basis size: 165\n",
      " mean: [1.56836]\n",
      " std-dev: [2.97816]\n",
      "------------------------------------------------------------\n",
      "Index   | Multi-indice                  | Part of variance  \n",
      "------------------------------------------------------------\n",
      "     77 | [0,6,0]                       | 0.125547\n",
      "     30 | [0,4,0]                       | 0.0742798\n",
      "      1 | [1,0,0]                       | 0.0739558\n",
      "    156 | [0,8,0]                       | 0.0502987\n",
      "    128 | [5,1,2]                       | 0.0425307\n",
      "    140 | [3,0,5]                       | 0.0392203\n",
      "     10 | [3,0,0]                       | 0.0260638\n",
      "    119 | [0,0,7]                       | 0.0241008\n",
      "    104 | [2,0,5]                       | 0.019967\n",
      "    155 | [1,0,7]                       | 0.0166214\n",
      "      7 | [0,2,0]                       | 0.0163905\n",
      "     89 | [5,0,2]                       | 0.0162789\n",
      "    120 | [8,0,0]                       | 0.0162193\n",
      "     92 | [4,1,2]                       | 0.0151717\n",
      "      9 | [0,0,2]                       | 0.0142158\n",
      "    148 | [1,7,0]                       | 0.0134511\n",
      "    133 | [4,1,3]                       | 0.0131993\n",
      "     52 | [0,3,2]                       | 0.011987\n",
      "     13 | [1,2,0]                       | 0.0118828\n",
      "    130 | [4,4,0]                       | 0.0117122\n",
      "    111 | [1,0,6]                       | 0.011137\n",
      "     43 | [2,1,2]                       | 0.0101898\n",
      "------------------------------------------------------------\n",
      "\n",
      "\n",
      "------------------------------------------------------------\n",
      "Component | Sobol index            | Sobol total index      \n",
      "------------------------------------------------------------\n",
      "        0 | 0.136113               | 0.593348              \n",
      "        1 | 0.27173                | 0.642526              \n",
      "        2 | 0.0586657              | 0.513889              \n",
      "------------------------------------------------------------\n",
      "\n",
      "\n",
      "######################\n",
      "Indices with model 3\n",
      " input dimension: 3\n",
      " output dimension: 1\n",
      " basis size: 30\n",
      " mean: [3.53063]\n",
      " std-dev: [3.57364]\n",
      "------------------------------------------------------------\n",
      "Index   | Multi-indice                  | Part of variance  \n",
      "------------------------------------------------------------\n",
      "      9 | [0,4,0]                       | 0.263998\n",
      "      4 | [3,0,0]                       | 0.181292\n",
      "     13 | [3,0,2]                       | 0.157298\n",
      "      1 | [1,0,0]                       | 0.145449\n",
      "     17 | [0,6,0]                       | 0.138433\n",
      "      5 | [1,0,2]                       | 0.0550224\n",
      "      3 | [0,2,0]                       | 0.0235085\n",
      "     20 | [3,0,4]                       | 0.0190338\n",
      "------------------------------------------------------------\n",
      "\n",
      "\n",
      "------------------------------------------------------------\n",
      "Component | Sobol index            | Sobol total index      \n",
      "------------------------------------------------------------\n",
      "        0 | 0.326811               | 0.564336              \n",
      "        1 | 0.43473                | 0.438209              \n",
      "        2 | 0.000467606            | 0.238459              \n",
      "------------------------------------------------------------\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "SI_1 = ot.FunctionalChaosSobolIndices(results_1)\n",
    "SI_2 = ot.FunctionalChaosSobolIndices(results_2)\n",
    "SI_3 = ot.FunctionalChaosSobolIndices(results_3)\n",
    "print('Indices with model 1')\n",
    "print( SI_1.summary())\n",
    "print ('######################')\n",
    "print('Indices with model 2')\n",
    "print( SI_2.summary())\n",
    "print ('######################')\n",
    "print('Indices with model 3')\n",
    "print(SI_3.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Reference results\n",
    "\n",
    "Comparisons of the computed Sobol indices with the reference ones (available for the Ishigami function)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reference indices\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'expectation': 3.5,\n",
       " 'variance': 13.844587940719254,\n",
       " 'S1': 0.31390519114781146,\n",
       " 'S2': 0.4424111447900409,\n",
       " 'S3': 0,\n",
       " 'S12': 0,\n",
       " 'S23': 0,\n",
       " 'S13': 0.2436836640621477,\n",
       " 'S123': 0,\n",
       " 'ST1': 0.5575888552099592,\n",
       " 'ST2': 0.4424111447900409,\n",
       " 'ST3': 0.2436836640621477}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def ishigamiSA(a,b):\n",
    "    '''Exact sensitivity indices of the Ishigami function for given a and b.'''\n",
    "    var = 1.0/2 + a**2/8 + b*np.pi**4/5 + b**2*np.pi**8/18\n",
    "    S1 = (1.0/2 + b*np.pi**4/5+b**2*np.pi**8/50)/var\n",
    "    S2 = (a**2/8)/var\n",
    "    S3 = 0\n",
    "    S13 = b**2*np.pi**8/2*(1.0/9-1.0/25)/var\n",
    "    exact = {\n",
    "            'expectation' : a/2,\n",
    "            'variance' : var,\n",
    "            'S1' : (1.0/2 + b*np.pi**4/5+b**2*np.pi**8.0/50)/var,\n",
    "            'S2' : (a**2/8)/var,\n",
    "            'S3' : 0,\n",
    "            'S12' : 0,\n",
    "            'S23' : 0,\n",
    "            'S13' : S13,\n",
    "            'S123' : 0,\n",
    "            'ST1' : S1 + S13,\n",
    "            'ST2' : S2,\n",
    "            'ST3' : S3 + S13\n",
    "            }\n",
    "    return exact\n",
    "\n",
    "a = 7.\n",
    "b = 0.1\n",
    "exact = ishigamiSA(a,b)\n",
    "print('Reference indices')\n",
    "exact"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# 2. Bootstrap technique to compute error\n",
    "## 2.1 Repetition\n",
    "In order to estimate the coefficient of variation of the PCE estimator of the Sobol indices, some repetitions can be done."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "inputDim = 3\n",
    "repet = 700\n",
    "input_names = ['x1', 'x2','x3']\n",
    "\n",
    "#database size\n",
    "N = 50\n",
    "    \n",
    "#Initialization\n",
    "L_First_Order = []\n",
    "L_Total_Index = []\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "#to choose randomly  the training and validation  set for the bootstrap  \n",
    "for j in range(repet):\n",
    "    \n",
    "    inputSample = distribution.getSample(N)\n",
    "    outputSample = g(inputSample)\n",
    "    basisSequenceFactory = ot.LARS()\n",
    "    fittingAlgorithm = ot.CorrectedLeaveOneOut()\n",
    "    approximationAlgorithm = ot.LeastSquaresMetaModelSelectionFactory(\n",
    "    basisSequenceFactory, fittingAlgorithm)\n",
    "    evaluationCoeffStrategy = ot.LeastSquaresStrategy(\n",
    "    ot.MonteCarloExperiment(N), approximationAlgorithm)\n",
    "    chaosalgo_3 = ot.FunctionalChaosAlgorithm(\n",
    "    inputSample, outputSample, distribution, adaptiveStrategy, evaluationCoeffStrategy)\n",
    "    chaosalgo_3.run()\n",
    "    results_3 = chaosalgo_3.getResult()\n",
    "    SI_3 = ot.FunctionalChaosSobolIndices(results_3)\n",
    "    \n",
    "    first_order = list(map(lambda i: SI_3.getSobolIndex(i), range(inputDim)))\n",
    "    total_index = list(map(lambda i: SI_3.getSobolTotalIndex(i), range(inputDim)))\n",
    "          \n",
    "    L_First_Order.append(first_order)\n",
    "    L_Total_Index.append(total_index)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "###########################\n",
      "\n",
      "Sobol index, first order (coefficient of variation \\%)\n",
      "\n",
      "x1 : 0.30366553716087774 (13.64626517184307\\%) \n",
      "\n",
      "x2 : 0.4726583511279388 (11.498426610941388\\%) \n",
      "\n",
      "x3 : 0.005583985845438181 (431.7181118018959\\%) \n",
      "\n",
      "First order sum = 0.7819078741342548\n",
      "\n",
      "Total Sobol index (coefficient of variation \\%):\n",
      "\n",
      "x1 : 0.5121297267165025 (14.058886589752928\\%) \n",
      "\n",
      "x2 : 0.491717710707018 (14.000096338332396\\%) \n",
      "\n",
      "x3 : 0.22206917621428054 (19.494544527223535\\%) \n",
      "\n",
      "Total Sobol index sum = 1.225916613637801\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#######post process\n",
    "L_First_Order = np.array(L_First_Order)\n",
    "L_Total_Index = np.array(L_Total_Index)\n",
    "\n",
    "#print('Sensitivity analysis with sparse PCE of degree'+str(degree)+'\\n')\n",
    "#print('training sample of size = '+str(size_data-size_validation)+'\\n')\n",
    "#print('validation sample of size = '+str(size_validation)+'\\n')\n",
    "j=0\n",
    "mean = L_First_Order[j*repet:(j+1)*repet].mean(axis = 0)\n",
    "std =  L_First_Order[j*repet:(j+1)*repet].std(axis = 0)\n",
    "cv = std/mean\n",
    "print(\"###########################\\n\")\n",
    "    \n",
    "print(\"Sobol index, first order (coefficient of variation \\%)\\n\")\n",
    "for i in range(inputDim):\n",
    "        print(input_names[i]+' : '+str(mean[i])+' ('+str(cv[i]*100)+'\\%) \\n')\n",
    "print(\"First order sum = \"+str(np.array(mean).sum())+'\\n')\n",
    "mean = L_Total_Index[j*repet:(j+1)*repet].mean(axis = 0)\n",
    "std =  L_Total_Index[j*repet:(j+1)*repet].std(axis = 0)\n",
    "cv = std/mean      \n",
    "print(\"Total Sobol index (coefficient of variation \\%):\\n\")\n",
    "for i in range(inputDim):\n",
    "        print(input_names[i]+' : '+str(mean[i])+' ('+str(cv[i]*100)+'\\%) \\n')\n",
    "print(\"Total Sobol index sum = \"+str(np.array(mean).sum())+\"\\n\")\n",
    "   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "This approch allows to estimate the variance of our estimator but it is in practice very costly as the PCE has to be rebuild using a new design of experiment at each repetition (evaluation of the numerical model $repet\\times N$). In order to reduce this cost one can estimate the variance using resampling approach knows as bootstrap."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## 2.2 Fixed database only once and reused with different training and validation set (Bootstrap approach)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "#database chosen only once\n",
    "inputSample = distribution.getSample(N)\n",
    "outputSample = g(inputSample)\n",
    "X=np.array(inputSample)\n",
    "Y=np.array(outputSample)\n",
    "\n",
    "\n",
    "#Initialization\n",
    "L_First_Order = []\n",
    "L_Total_Index = []\n",
    "\n",
    "\n",
    "\n",
    "#to choose randomly  the training set for the bootstrap  \n",
    "for j in range(repet):\n",
    "    \n",
    "    Ind_train = np.random.choice(N,N,replace=True)\n",
    "    #to choose the training set associated \n",
    "    X_train = X[Ind_train,:]\n",
    "    Y_train = Y[Ind_train].reshape((N,1))\t\n",
    "\n",
    "        \n",
    "    basisSequenceFactory = ot.LARS()\n",
    "    fittingAlgorithm = ot.CorrectedLeaveOneOut()\n",
    "    approximationAlgorithm = ot.LeastSquaresMetaModelSelectionFactory(\n",
    "    basisSequenceFactory, fittingAlgorithm)\n",
    "    evaluationCoeffStrategy = ot.LeastSquaresStrategy(\n",
    "    ot.MonteCarloExperiment(N), approximationAlgorithm)\n",
    "    chaosalgo_3 = ot.FunctionalChaosAlgorithm(\n",
    "    X_train, Y_train, distribution, adaptiveStrategy, evaluationCoeffStrategy)\n",
    "    chaosalgo_3.run()\n",
    "    \n",
    "    #Get the result:\n",
    "    results = chaosalgo_3.getResult()\n",
    "    sensitivityAnalysis = ot.FunctionalChaosSobolIndices(results)\n",
    "    responseSurface = results.getMetaModel()\n",
    "  \n",
    "    sensitivityAnalysis = ot.FunctionalChaosSobolIndices(results)\n",
    "    first_order = list(map(lambda i: sensitivityAnalysis.getSobolIndex(i), range(inputDim)))\n",
    "    total_index = list(map(lambda i: sensitivityAnalysis.getSobolTotalIndex(i), range(inputDim)))\n",
    "         \n",
    "       \n",
    "    L_First_Order.append(first_order)\n",
    "    L_Total_Index.append(total_index)\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "###########################\n",
      "\n",
      "Sobol index, first order (coefficient of variation \\%)\n",
      "\n",
      "x1 : 0.18859744940164708 (54.39965840776715\\%) \n",
      "\n",
      "x2 : 0.4591546214428681 (29.017970819305923\\%) \n",
      "\n",
      "x3 : 0.010770464079074836 (238.03180082061198\\%) \n",
      "\n",
      "First order sum = 0.65852253492359\n",
      "\n",
      "Total Sobol index (coefficient of variation \\%):\n",
      "\n",
      "x1 : 0.44054606037418703 (30.133027045169293\\%) \n",
      "\n",
      "x2 : 0.6928037006893216 (21.390653858631907\\%) \n",
      "\n",
      "x3 : 0.3421588543229924 (45.10299092312125\\%) \n",
      "\n",
      "Total Sobol index sum = 1.475508615386501\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#######post process\n",
    "L_First_Order = np.array(L_First_Order)\n",
    "L_Total_Index = np.array(L_Total_Index)\n",
    "\n",
    "\n",
    "\n",
    "j=0\n",
    "mean = L_First_Order[j*repet:(j+1)*repet].mean(axis = 0)\n",
    "std =  L_First_Order[j*repet:(j+1)*repet].std(axis = 0)\n",
    "cv = std/mean\n",
    "print(\"###########################\\n\")\n",
    "    \n",
    "print(\"Sobol index, first order (coefficient of variation \\%)\\n\")\n",
    "for i in range(inputDim):\n",
    "        print(input_names[i]+' : '+str(mean[i])+' ('+str(cv[i]*100)+'\\%) \\n')\n",
    "print(\"First order sum = \"+str(np.array(mean).sum())+'\\n')\n",
    "mean = L_Total_Index[j*repet:(j+1)*repet].mean(axis = 0)\n",
    "std =  L_Total_Index[j*repet:(j+1)*repet].std(axis = 0)\n",
    "cv = std/mean      \n",
    "print(\"Total Sobol index (coefficient of variation \\%):\\n\")\n",
    "for i in range(inputDim):\n",
    "        print(input_names[i]+' : '+str(mean[i])+' ('+str(cv[i]*100)+'\\%) \\n')\n",
    "print(\"Total Sobol index sum = \"+str(np.array(mean).sum())+\"\\n\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "It can be seen that bootstrap approach offers a correct approximation of the variance of the PCE estimator of the Sobol indices with a design of experiment of size only $N$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Try to do the same test and increase the value of N in order to decrease the coefficient of variation"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Diaporama",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
