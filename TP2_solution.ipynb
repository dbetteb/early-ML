{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "TP2_solution.ipynb",
      "private_outputs": true,
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/dbetteb/early-ML/blob/master/TP2_solution.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i_UvVJOP9uJi"
      },
      "source": [
        "# Imports"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vmaMgUEd9xpm"
      },
      "source": [
        "import numpy as np\n",
        "import datetime, os\n",
        "from tensorflow.keras.utils import get_file\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from tensorflow.keras import Input\n",
        "from tensorflow.keras.models import Sequential, Model\n",
        "from tensorflow.keras.layers import Dense, Activation, Conv2D, MaxPooling2D, Flatten, Dropout, GlobalAveragePooling2D\n",
        "from tensorflow.keras.losses import SparseCategoricalCrossentropy, CategoricalCrossentropy\n",
        "from tensorflow.keras.optimizers import Adam, RMSprop, SGD\n",
        "from tensorflow.keras.callbacks import EarlyStopping, TensorBoard\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator, array_to_img, img_to_array, load_img\n",
        "from tensorflow.keras.models import load_model\n",
        "from tensorflow.keras.callbacks import EarlyStopping, TensorBoard\n",
        "from sklearn.metrics import balanced_accuracy_score, confusion_matrix\n",
        "import matplotlib.pyplot as plt\n",
        "import datetime\n",
        "\n",
        "!wget https://github.com/gaudel/NN/raw/main/pretrained_model.h5\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KMLafIyo92_m"
      },
      "source": [
        "# Usefull functions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HpPNMeZf91h4"
      },
      "source": [
        "def build_CNN(input_dim, output_dim, lr=0.001):\n",
        "  model = Sequential()\n",
        "\n",
        "  model.add(Conv2D(32, (3, 3), input_shape=input_dim, activation=\"relu\"))\n",
        "  model.add(MaxPooling2D(pool_size=(2,2)))\n",
        "  model.add(Dropout(rate=0.1))\n",
        "\n",
        "  model.add(Conv2D(64, (3, 3), activation=\"relu\"))\n",
        "  model.add(MaxPooling2D(pool_size=(2,2)))\n",
        "  model.add(Dropout(rate=0.1))\n",
        "\n",
        "  model.add(Conv2D(64, (3, 3), activation=\"relu\"))\n",
        "  model.add(Dropout(rate=0.1))\n",
        "\n",
        "  model.add(Flatten())\n",
        "  model.add(Dense(64, activation=\"relu\"))\n",
        "  model.add(Dropout(rate=0.1))\n",
        "\n",
        "  model.add(Dense(output_dim))\n",
        "\n",
        "  model.compile(loss=CategoricalCrossentropy(from_logits=True), optimizer='rmsprop', metrics=['accuracy'])\n",
        "\n",
        "  return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GZHzQpPU9-a3"
      },
      "source": [
        "def build_CNN_from_pretrained(file_name, output_dim, lr=0.001):\n",
        "  model = load_model(file_name)\n",
        "  model.pop()\n",
        "\n",
        "  model.add(Dense(output_dim))\n",
        "\n",
        "  model.compile(loss=CategoricalCrossentropy(from_logits=True), optimizer='adam', metrics=['accuracy'])\n",
        "  return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ELdBI7nO-EGl"
      },
      "source": [
        "# Main"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m0ZKHTPF-uBt"
      },
      "source": [
        "## Hyper-parameters"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hDmb1ezx-sjF"
      },
      "source": [
        "epochs = 50\n",
        "batch_size = 64"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R5aXh-otABjp"
      },
      "source": [
        "## Initialization"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UorhZH0LAD_f"
      },
      "source": [
        "rng = np.random.default_rng()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yxrWMoei-G7N"
      },
      "source": [
        "## Data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "az2KhSRiv5p7"
      },
      "source": [
        "### Download data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2UMXiuTav50U"
      },
      "source": [
        "data_f = get_file('data.zip', 'https://github.com/gaudel/NN/raw/main/data.zip', extract=True)\n",
        "\n",
        "def foo(data_src):\n",
        "  if type(data_src) == str:\n",
        "    images, labels = next(ImageDataGenerator(rescale=1./255).flow_from_directory(data_f[:-4] + '/' + data_src, batch_size=25))\n",
        "  else:\n",
        "    images, labels = next(data_src)\n",
        "\n",
        "  print(f'shape of features: {images.shape[1:]}')\n",
        "  print(f'shape of labels: {labels.shape[1:]}')\n",
        "  class_names = ['cat', 'dog']\n",
        "  plt.figure(figsize=(10,10))\n",
        "  for i in range(25):\n",
        "      plt.subplot(5,5,i+1)\n",
        "      plt.xticks([])\n",
        "      plt.yticks([])\n",
        "      plt.grid(False)\n",
        "      plt.imshow(images[i], cmap=plt.cm.binary)\n",
        "      plt.xlabel(class_names[np.argmax(labels[i])] + f' ({labels[i]})')\n",
        "  plt.show()\n",
        "\n",
        "print('--- train data ---')\n",
        "foo('train')\n",
        "\n",
        "print('--- validation data ---')\n",
        "foo('valid')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yv9w3_Qzv5-3"
      },
      "source": [
        "### Data generators"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mXJTLXQMfVrN"
      },
      "source": [
        "#Q2: Ajouter l'attribut rescale aux générateurs\n",
        "#Q3: Ajouter des attributs pour faire de l'augmeentation de données\n",
        "train_generator = ImageDataGenerator(rescale=1/255,\n",
        "                                     rotation_range=20,\n",
        "                                     width_shift_range=0.2,\n",
        "                                     height_shift_range=0.2,\n",
        "                                     horizontal_flip=True,\n",
        "                                     zoom_range=0.1)\n",
        "valid_generator = ImageDataGenerator(rescale=1/255)\n",
        "\n",
        "#Q2: Ajouter les attributs \"target_size\" et \"batch_size\"\n",
        "train_flow = train_generator.flow_from_directory(data_f[:-4]+'/train', target_size=(32, 32), batch_size=batch_size)\n",
        "valid_flow = valid_generator.flow_from_directory(data_f[:-4]+'/valid', target_size=(32, 32), batch_size=batch_size)\n",
        "\n",
        "print('--- train data ---')\n",
        "foo(train_flow)\n",
        "\n",
        "print('--- validation data ---')\n",
        "foo(valid_flow)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uDwbjjBADR5t"
      },
      "source": [
        "## Build"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vTfbZm_kDSCJ"
      },
      "source": [
        "from_scratch = True\n",
        "if from_scratch:\n",
        "  # Q2: compléter l'appel à la fonction build_CNN()\n",
        "  cnn_model = build_CNN((32, 32, 3), 2)\n",
        "  label = 'from_scratch'\n",
        "else:\n",
        "  cnn_model = build_CNN_from_pretrained(\"pretrained_model.h5\", 2)\n",
        "  label = 'from_pretrained'\n",
        "cnn_model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NBsopydYDSKT"
      },
      "source": [
        "## Fit & evaluate"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W6TCTaEzDSS2"
      },
      "source": [
        "#Q2: compléter l'appel aux fonctions fit() et evaluate()\n",
        "tensorboard_callback = TensorBoard(log_dir='logs/' + label + '__' + datetime.datetime.now().strftime(\"%d-%m_%Hh%M\"), histogram_freq=int(epochs/10))\n",
        "\n",
        "cnn_model.fit(\n",
        "        train_flow,\n",
        "        epochs=epochs,\n",
        "        validation_data=valid_flow,\n",
        "        callbacks=[tensorboard_callback])\n",
        "\n",
        "cnn_model.evaluate(valid_flow, verbose=2)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KQ1mhkw--mzg"
      },
      "source": [
        "# Tensorboard"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TK-4z9vk_byM"
      },
      "source": [
        "## Initialization"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ENhrAk2iDyy4"
      },
      "source": [
        "# Load the TensorBoard notebook extension\n",
        "%load_ext tensorboard"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZqbcweOUBcd7"
      },
      "source": [
        "## Start tensorboard"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iCV7neA9-vhT"
      },
      "source": [
        "%tensorboard --logdir logs"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A-j0HEph_pAN"
      },
      "source": [
        "# Model to load"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d7SwuXk5_w-I"
      },
      "source": [
        "## data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hTGH3rFt_rjH"
      },
      "source": [
        "from tensorflow.keras.datasets import cifar10\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "\n",
        "(train_images, train_labels), (test_images, test_labels) = cifar10.load_data()\n",
        "train_labels, test_labels = to_categorical(train_labels), to_categorical(test_labels)\n",
        "\n",
        "train_generator = ImageDataGenerator(rescale=1/255,\n",
        "                                     rotation_range=20,\n",
        "                                     width_shift_range=0.2,\n",
        "                                     height_shift_range=0.2,\n",
        "                                     horizontal_flip=True,\n",
        "                                     zoom_range=0.1)\n",
        "valid_generator = ImageDataGenerator(rescale=1/255)\n",
        "\n",
        "#Q2: Ajouter les attributs \"target_size\" et \"batch_size\"\n",
        "train_flow = train_generator.flow(train_images, train_labels, batch_size=batch_size)\n",
        "valid_flow = valid_generator.flow(test_images, test_labels, batch_size=batch_size)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "doNZzOuP_5cj"
      },
      "source": [
        "## build"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mjx2Z2v___WO"
      },
      "source": [
        "cnn_model = build_CNN((32, 32, 3), 10)\n",
        "#cnn_model.compile(loss=\"sparse_categorical_crossentropy\", optimizer=Adam(0.001), metrics=['accuracy'])\n",
        "label = 'pre_trained'\n",
        "cnn_model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WXqzrm-OAG1B"
      },
      "source": [
        "## fit"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N6MMOLG8AKUY"
      },
      "source": [
        "tensorboard_callback = TensorBoard(log_dir='logs/' + label + '__' + datetime.datetime.now().strftime(\"%d-%m_%Hh%M\"), histogram_freq=int(epochs/10))\n",
        "\n",
        "cnn_model.fit(\n",
        "        train_flow,\n",
        "        epochs=20,\n",
        "        validation_data=valid_flow,\n",
        "        callbacks=[tensorboard_callback])\n",
        "\n",
        "cnn_model.evaluate(valid_flow, verbose=2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vtmE-lsvErXi"
      },
      "source": [
        "## save"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iQA_x4EqAqsm"
      },
      "source": [
        "cnn_model.save('my_model.h5')\n",
        "\n",
        "from google.colab import files\n",
        "files.download('my_model.h5') "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gV_Ov1XDfqbN"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}